{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# For cleaning the text\r\n",
    "import spacy\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import regex as re\r\n",
    "import string\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train = pd.read_csv(\"../input/explore_train.csv\")\r\n",
    "test = pd.read_csv(\"../input/explore_test.csv\")\r\n",
    "all_data = [train, test]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_keyword</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_keyword</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword                                               text  target\n",
       "0  no_keyword  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1  no_keyword             Forest fire near La Ronge Sask. Canada       1\n",
       "2  no_keyword  All residents asked to 'shelter in place' are ...       1\n",
       "3  no_keyword  13,000 people receive #wildfires evacuation or...       1\n",
       "4  no_keyword  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clean the text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#nlp = spacy.load(\"en\")\r\n",
    "sp = spacy.load('en_core_web_sm')\r\n",
    "\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('punkt')\r\n",
    "\r\n",
    "# spacy (362 words)\r\n",
    "spacy_st = sp.Defaults.stop_words\r\n",
    "# nltk(179 words)\r\n",
    "nltk_st = stopwords.words('english')\r\n",
    "\r\n",
    "def clean(tweet, http = True, punc = True, lem = True, stop_w = True):\r\n",
    "    \r\n",
    "    if http is True:\r\n",
    "        tweet = re.sub(\"https?:\\/\\/t.co\\/[A-Za-z0-9]*\", '', tweet)\r\n",
    "\r\n",
    "    # stop words\r\n",
    "    # in here I changed the placement of lower for those of you who want to use\r\n",
    "    # Cased BERT later on.\r\n",
    "    if stop_w == 'nltk':\r\n",
    "        tweet = [word for word in word_tokenize(tweet) if not word.lower() in nltk_st]\r\n",
    "        tweet = ' '.join(tweet)\r\n",
    "\r\n",
    "    elif stop_w == 'spacy':\r\n",
    "        tweet = [word for word in word_tokenize(tweet) if not word.lower() in spacy_st]\r\n",
    "        tweet = ' '.join(tweet)\r\n",
    "\r\n",
    "    # lemmitizing\r\n",
    "    if lem == True:\r\n",
    "        lemmatized = [word.lemma_ for word in sp(tweet)]\r\n",
    "        tweet = ' '.join(lemmatized)\r\n",
    "\r\n",
    "    # punctuation removal\r\n",
    "    if punc is True:\r\n",
    "        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\r\n",
    "        \r\n",
    "    # removing extra space\r\n",
    "    tweet = re.sub(\"\\s+\", ' ', tweet)\r\n",
    "    \r\n",
    "    return tweet"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mónica\n",
      "[nltk_data]     Emmanuelle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mónica\n",
      "[nltk_data]     Emmanuelle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for dataframe in all_data:\r\n",
    "    dataframe['cleaned_text'] = dataframe.text.apply(lambda x: clean(x, lem = False, stop_w = 'nltk', http = True, punc = True))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "try:\r\n",
    "    for dataframe in all_data:\r\n",
    "        dataframe.drop(\"text\", axis=1, inplace=True)\r\n",
    "        dataframe.drop(\"keyword\", axis=1, inplace=True)\r\n",
    "except:\r\n",
    "    print(\"Columns alredy removed\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for dataframe in all_data:\r\n",
    "    dataframe[\"cleaned_text\"] = dataframe[\"cleaned_text\"].str.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                       cleaned_text\n",
       "0       1       deeds reason earthquake may allah forgive us\n",
       "1       1              forest fire near la ronge sask canada\n",
       "2       1  residents asked shelter place notified officer...\n",
       "3       1  13000 people receive wildfires evacuation orde...\n",
       "4       1  got sent photo ruby alaska smoke wildfires pou..."
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kills 28 china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text\n",
       "0                        happened terrible car crash\n",
       "1  heard earthquake different cities stay safe ev...\n",
       "2  forest fire spot pond geese fleeing across str...\n",
       "3              apocalypse lighting spokane wildfires\n",
       "4             typhoon soudelor kills 28 china taiwan"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "train.to_csv(\"../input/cleaned_train.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "test.to_csv(\"../input/cleaned_test.csv\", index= False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}